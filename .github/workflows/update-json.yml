name: Update IPTV JSON List
on:
  workflow_dispatch:
  schedule:
    - cron: '*/20 * * * *'

jobs:
  generate-json:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v3

      - name: Fetch and Convert M3U to JSON
        run: |
          curl -s -L "https://raw.githubusercontent.com/nghehoang007-wq/HFB321/refs/heads/main/all.m3u" > raw.m3u
          
          cat << 'EOF' > convert.py
          import json
          import re
          from datetime import datetime, timedelta, timezone

          # L·∫•y ng√†y hi·ªán t·∫°i
          tz_vn = timezone(timedelta(hours=7))
          now_vn = datetime.now(tz_vn)
          today_str = now_vn.strftime("%d/%m")

          # H√†m T·ª± ƒê·ªông Vi·∫øt T·∫Øt T√™n ƒê·ªôi B√≥ng
          def shorten_name(name):
              name = name.strip()
              known = {
                  "Manchester United": "Man Utd", "Manchester City": "Man City", "Paris Saint Germain": "PSG",
                  "Wolverhampton Wanderers": "Wolves", "Wolverhampton": "Wolves", "Borussia Dortmund": "Dortmund",
                  "Borussia Monchengladbach": "M'gladbach", "Nottingham Forest": "N. Forest", "Bayer 04 Leverkusen": "Leverkusen",
                  "Eintracht Frankfurt": "E. Frankfurt", "Sporting Kansas City": "Sporting KC", "Club Deportivo Guadalajara": "Guadalajara",
                  "Preah Khan Reach Svay Rieng FC": "Svay Rieng", "Crystal Palace": "C. Palace", "Aston Villa": "A. Villa",
                  "Sheffield Wednesday": "Sheff Wed", "Sheffield United": "Sheff Utd", "Los Angeles FC": "LAFC", "Inter Miami CF": "Inter Miami"
              }
              for k, v in known.items():
                  if k.lower() in name.lower():
                      return v

              words_to_remove = ["FC", "CF", "SC", "AFC", "Club"]
              words = name.split()
              if len(words) > 1:
                  words = [w for w in words if w not in words_to_remove]
              res = " ".join(words)
              
              if len(res) > 13 and len(words) >= 2:
                  res = f"{words[0][0]}. " + " ".join(words[1:])
              if len(res) > 14:
                  res = res[:12] + ".."
              return res

          # H√†m l·∫•y th·ªùi gian ƒë·ªÉ s·∫Øp x·∫øp
          def get_sort_key(t_str):
              m = re.search(r'(\d{1,2})[hH:](\d{2})', t_str)
              if m:
                  return (int(m.group(1)), int(m.group(2)))
              return (99, 99)

          data = {
            "id": "HFB",
            "url": "http://hfb123.netlify.app/MT.json",
            "name": "HFB",
            "color": "#1cb57a",
            "description": "HFB - Trang web ph√°t s√≥ng b√≥ng ƒë√° tr·ª±c tuy·∫øn mi·ªÖn ph√≠.",
            "image": {
              "url": "https://t4.ftcdn.net/jpg/02/11/51/53/360_F_211515361_bnIbyKadClzn3hJT0zCPPuPApcG7k3lC.jpg"
            },
            "groups": [],
            "sorts": [],
            "notice": {
              "id": "notice",
              "link": "",
              "icon": "",
              "closeable": True
            },
            "option": {
              "save_history": False,
              "save_search_history": False,
              "save_wishlist": False
            }
          }

          try:
              with open('raw.m3u', 'r', encoding='utf-8') as f:
                  lines = [line.strip() for line in f if line.strip()]
          except Exception as e:
              lines = []

          # Dictionary l∆∞u tr·ªØ c√°c tr·∫≠n ƒë·∫•u theo t·ª´ng Ng√†y -> T√™n Tr·∫≠n
          date_groups = {}
          match_uid = 1
          stream_uid = 1

          for i in range(len(lines)):
              line = lines[i]
              
              if line.startswith('#EXTINF') and 'Socolive' in line:
                  parts = line.split(',', 1)
                  if len(parts) > 1:
                      display_text = parts[1].strip()
                      
                      # T√°ch Gi·ªù, BLV, T√™n Tr·∫≠n
                      match_info = re.match(r'(.*?):\s*\[(.*?)\]\s*(.*)', display_text)
                      
                      if match_info:
                          time_str_full = match_info.group(1).strip()
                          blv_name = match_info.group(2).strip()
                          raw_match_name = match_info.group(3).strip()
                      else:
                          time_str_full = "00h00"
                          blv_name = "BLV Socolive"
                          raw_match_name = display_text

                      # T√°ch Gi·ªù v√† Ng√†y
                      m_time = re.search(r'(\d{1,2}[hH:]\d{2})(?:-(.*?))?$', time_str_full)
                      if m_time:
                          time_only = m_time.group(1).replace(":", "h")
                          date_only = m_time.group(2).strip() if m_time.group(2) else today_str
                      else:
                          time_only = "00h00"
                          date_only = today_str
                          
                      d_parts = date_only.split('/')
                      if len(d_parts) == 2:
                          date_only = f"{int(d_parts[0]):02d}/{int(d_parts[1]):02d}"

                      # T√°ch 2 ƒë·ªôi
                      teams = re.split(r'(?i)\s+vs\s+', raw_match_name, maxsplit=1)
                      if len(teams) == 2:
                          team1 = shorten_name(teams[0])
                          team2 = shorten_name(teams[1])
                      else:
                          team1 = shorten_name(raw_match_name)
                          team2 = ""

                      if i + 1 < len(lines) and lines[i+1].startswith('http'):
                          raw_url = lines[i+1]
                          
                          # 1. S·ª¨ D·ª§NG TR·ª∞C TI·∫æP LINK T·ª™ M3U L√ÄM LU·ªíNG CH√çNH
                          primary_url = raw_url
                          
                          # 2. T√åM ID (D√ÉY S·ªê) TRONG LINK ƒê·ªÇ T·∫†O LU·ªíNG D·ª∞ PH√íNG NIUES
                          id_match = re.search(r'(\d{5,8})', raw_url)
                          if id_match:
                              stream_id = id_match.group(1)
                              backup_url = f"https://pull.niues.live/live/stream-{stream_id}_lhd.m3u8"
                          else:
                              backup_url = ""
                          
                          # Kh√≥a gom nh√≥m: 1 tr·∫≠n ƒë∆∞·ª£c ƒë·ªãnh danh b·ªüi Ng√†y + Gi·ªù + T√™n Tr·∫≠n g·ªëc
                          match_key = f"{time_only}-{raw_match_name}"
                          
                          if date_only not in date_groups:
                              date_groups[date_only] = {}
                          
                          # N·∫æU TR·∫¨N N√ÄY CH∆ØA C√ì TRONG DANH S√ÅCH -> T·∫†O KHUNG M·ªöI
                          if match_key not in date_groups[date_only]:
                              
                              # CH·ªà C√íN NH√ÉN TH·ªúI GIAN V√Ä T√äN 2 ƒê·ªòI
                              labels_list = [
                                  { "position": "bottom-center", "text": time_only, "color": "#FF0000", "text_color": "#FFFFFF" }
                              ]
                              
                              # N·∫°p ƒê·ªôi 1 v√†o tr∆∞·ªõc (n·∫±m d∆∞·ªõi)
                              if team1:
                                  labels_list.append({ "position": "center-left", "text": team1, "color": "#80000000", "text_color": "#FFFFFF" })
                                  
                              # N·∫°p ƒê·ªôi 2 v√†o sau c√πng -> S·∫Ω ƒë√® l√™n ƒê·ªôi 1 n·∫øu qu√° d√†i
                              if team2:
                                  labels_list.append({ "position": "center-right", "text": team2, "color": "#80000000", "text_color": "#FFFFFF" })

                              channel_obj = {
                                "id": f"ch-{match_uid}",
                                "name": raw_match_name,
                                "labels": labels_list,
                                "description": f"Socolive ‚Ä¢ {time_only}",
                                "image": {
                                  "url": "https://raw.githubusercontent.com/nghehoang007-wq/HFB321/main/HFB/Thump/nguonphat5.png",
                                  "height": 360, "width": 640, "display": "cover", "shape": "square"
                                },
                                "type": "single",
                                "display": "thumbnail-only",
                                "sources": [
                                  {
                                    "id": f"src-{match_uid}",
                                    "name": "Socolive",
                                    "contents": [
                                      {
                                        "id": f"cnt-{match_uid}",
                                        "name": raw_match_name,
                                        "streams": [
                                          {
                                            "id": f"strm-{match_uid}",
                                            "name": "Danh s√°ch lu·ªìng", 
                                            "stream_links": []
                                          }
                                        ]
                                      }
                                    ]
                                  }
                                ]
                              }
                              date_groups[date_only][match_key] = {
                                  "sort_key": get_sort_key(time_only),
                                  "channel": channel_obj
                              }
                              match_uid += 1
                          
                          # ƒê·∫®Y LINK M3U8 V√ÄO TR·∫¨N ƒê·∫§U (Bao g·ªìm link Ch√≠nh v√† D·ª± ph√≤ng)
                          target_stream_links = date_groups[date_only][match_key]["channel"]["sources"][0]["contents"][0]["streams"][0]["stream_links"]
                          is_first_blv = len(target_stream_links) == 0
                          
                          # ƒê·∫©y lu·ªìng ch√≠nh (L·∫•y t·ª´ file M3U)
                          primary_link_obj = {
                              "id": f"lnk-{stream_uid}-main",
                              "name": f"{blv_name} (Ch√≠nh)",
                              "type": "hls",
                              "default": is_first_blv, 
                              "url": primary_url,
                              "request_headers": [
                                  { "key": "Referer", "value": "https://bunchatv3.com/" }
                              ]
                          }
                          target_stream_links.append(primary_link_obj)
                          
                          # ƒê·∫©y lu·ªìng d·ª± ph√≤ng (N·∫øu l·∫•y ƒë∆∞·ª£c ID)
                          if backup_url:
                              backup_link_obj = {
                                  "id": f"lnk-{stream_uid}-backup",
                                  "name": f"{blv_name} (D·ª± ph√≤ng)",
                                  "type": "hls",
                                  "default": False, 
                                  "url": backup_url,
                                  "request_headers": [
                                      { "key": "Referer", "value": "https://bunchatv3.com/" }
                                  ]
                              }
                              target_stream_links.append(backup_link_obj)
                          
                          stream_uid += 1

          # S·∫Øp x·∫øp Group Ng√†y
          def date_sort_key(d_str):
              parts = d_str.split('/')
              if len(parts) == 2:
                  return (int(parts[1]), int(parts[0]))
              return (99, 99)

          sorted_dates = sorted(date_groups.keys(), key=date_sort_key)

          # Kh·ªüi t·∫°o d·ªØ li·ªáu JSON Final
          for d in sorted_dates:
              group_name = f"üî¥ H√¥m nay ({d})" if d == today_str else f"üî¥ Ng√†y {d}"
              
              sorted_matches = sorted(date_groups[d].values(), key=lambda x: x["sort_key"])
              
              data['groups'].append({
                  "id": f"group-{d.replace('/', '')}",
                  "name": group_name,
                  "display": "vertical",
                  "grid_number": 2,
                  "channels": [item["channel"] for item in sorted_matches]
              })

          with open('MT.json', 'w', encoding='utf-8') as f:
              json.dump(data, f, ensure_ascii=False, indent=2)
          EOF
          
          python3 convert.py
          
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git add MT.json
          git commit -m "UI: Use raw M3U link as primary, generate fallback automatically" || echo "No changes to commit"
          git push
