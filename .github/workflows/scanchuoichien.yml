name: Generate M3U from ChuoiChien
on:
  workflow_dispatch:
  schedule:
    - cron: '*/20 * * * *'

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v3

      - name: Install Dependencies
        # Đổi vũ khí: Dùng curl_cffi siêu mạnh để xuyên thủng Cloudflare
        run: pip install curl_cffi beautifulsoup4

      - name: Run ChuoiChien Scraper
        run: |
          cat << 'EOF' > scraper.py
          from curl_cffi import requests
          from bs4 import BeautifulSoup
          import re
          import unicodedata

          TARGET_URL = "https://live16.chuoichientv.com/lich-thi-dau"
          URL_PREFIX = "https://gckc0525.edgemaxcdn.org/live/"
          URL_SUFFIX = ".flv"

          def generate_stream_id(blv_name):
              name = blv_name.strip().lower()
              no_accent = unicodedata.normalize('NFKD', name).encode('ASCII', 'ignore').decode('utf-8')
              return re.sub(r'[^a-z0-9]', '', no_accent)

          try:
              print(f"Đang cào dữ liệu từ: {TARGET_URL}")
              
              # Dùng impersonate="chrome110" để ngụy trang thành người dùng Chrome thật
              response = requests.get(TARGET_URL, impersonate="chrome110", timeout=30)
              html = response.text
              
              # Bộ phận kiểm tra: Xem có bị Cloudflare tóm cổ không
              if len(html) < 2000 or "Just a moment" in html or "Cloudflare" in html:
                  print("⚠️ CẢNH BÁO: Đã bị Cloudflare hoặc hệ thống chống Bot chặn lại!")
                  print("Mã HTML trả về (500 ký tự đầu):", html[:500])
              
              soup = BeautifulSoup(html, 'html.parser')
              m3u_lines = ["#EXTM3U"]
              count = 0
              
              matches = soup.select('a[href*="/live/"]')
              
              for match in matches:
                  try:
                      team_divs = match.select('div.font-bold.text-white')
                      if len(team_divs) < 2:
                          continue
                      team1 = team_divs[0].get_text(strip=True)
                      team2 = team_divs[1].get_text(strip=True)
                      match_name = f"{team1} vs {team2}"

                      time_span = match.select_one('span.text-green-300')
                      time_str = time_span.get_text(strip=True).replace(' ', '-').replace(':', 'h') if time_span else "00:00"

                      blv_span = match.select_one('span.blv-info')
                      if not blv_span:
                          continue 
                          
                      blv_name = blv_span.get_text(strip=True)
                      if not blv_name:
                          continue

                      stream_id = generate_stream_id(blv_name)
                      stream_url = f"{URL_PREFIX}{stream_id}{URL_SUFFIX}"

                      display_text = f"ChuoiChien {time_str}: [{blv_name}] {match_name}"
                      m3u_lines.append(f'#EXTINF:-1 group-title="ChuoiChien",{display_text}')
                      m3u_lines.append(stream_url)
                      count += 1
                      
                  except Exception as ex:
                      continue

              with open('chuoichientv.m3u', 'w', encoding='utf-8') as f:
                  f.write("\n".join(m3u_lines))
                  
              print(f"✅ Quét thành công! Cào được {count} luồng phát từ Chuối Chiên TV.")

          except Exception as e:
              print(f"❌ Lỗi: {e}")
              with open('chuoichientv.m3u', 'w', encoding='utf-8') as f:
                  f.write("#EXTM3U\n")
          EOF
          
          python3 scraper.py

      - name: Commit and Push
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git add chuoichientv.m3u
          git commit -m "Auto Scrape ChuoiChien TV using curl_cffi" || echo "No changes"
          git push
