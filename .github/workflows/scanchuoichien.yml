name: Generate JSON from ChuoiChien
on:
  workflow_dispatch:
  schedule:
    - cron: '*/20 * * * *'

jobs:
  build:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v3

      - name: Install Dependencies
        # T√≠ch h·ª£p th√™m Pillow - "Photoshop" c·ªßa Python
        run: pip install curl_cffi python-dateutil Pillow

      - name: Run ChuoiChien JSON Factory
        run: |
          # D·ªçn s·∫°ch v√† t·∫°o m·ªõi 2 th∆∞ m·ª•c: ch·ª©a link l√°ch lu·∫≠t v√† ch·ª©a ·∫£nh x·ªãn
          rm -rf stream thumbs
          mkdir stream thumbs
          
          cat << 'EOF' > scraper.py
          import os
          import json
          import re
          import io
          from PIL import Image
          from datetime import datetime, timezone, timedelta
          from curl_cffi import requests
          from dateutil import parser

          # ================= C·∫§U H√åNH API =================
          API_URL = "https://api.chuoichientv.com/v1/matches?page=1&limit=100&sport=&type=blv"
          BASE_REMOTE_URL = "https://raw.githubusercontent.com/nghehoang007-wq/HFB321/main/stream/" 
          BASE_THUMB_URL = "https://raw.githubusercontent.com/nghehoang007-wq/HFB321/main/thumbs/"

          HEADERS = {
              "Authorization": "Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJndWVzdElkIjoiZTM0Zjk3ZmQtNWMxMC00MGEzLWE1OGYtZDE3MmQwMmIxNDZjIiwidHlwZSI6Imd1ZXN0IiwiaXAiOiIxNjIuMTU5Ljk4LjIyMCIsInVzZXJBZ2VudCI6Ik1vemlsbGEvNS4wIChXaW5kb3dzIE5UIDEwLjA7IFdpbjY0OyB4NjQpIEFwcGxlV2ViS2l0LzUzNy4zNiAoS0hUTUwsIGxpa2UgR2Vja28pIENocm9tZS8xMzEuMC4wLjAgU2FmYXJpLzUzNy4zNiIsIm5hbWUiOiJCw7puIMSQ4buPIDQ1MyIsInRpbWVzdGFtcCI6MTc3MjI5MTc4NzEwNCwiaWF0IjoxNzcyMjkxNzg3LCJleHAiOjE4MDM4Mjc3ODd9.iHhwdQaDRcrjyRfCVGCbSZb6dFj-EuzJblTD1wmttV0",
              "Origin": "https://live16.chuoichientv.com",
              "Referer": "https://live16.chuoichientv.com/",
              "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
          }

          tz_vn = timezone(timedelta(hours=7))

          def shorten_name(name):
              name = str(name).strip()
              known = {"Manchester United": "Man Utd", "Manchester City": "Man City", "Barcelona": "Barca", "Villarreal": "Villarr"}
              for k, v in known.items():
                  if k.lower() in name.lower(): return v
              return name[:12] + ".." if len(name) > 13 else name

          try:
              print("ƒêang kh·ªüi ƒë·ªông quy tr√¨nh b√≥c t√°ch API & X∆∞·ªüng t·∫°o ·∫£nh...")
              
              # T·∫¢I ·∫¢NH N·ªÄN CHU·∫®N 1 L·∫¶N DUY NH·∫§T
              base_bg_url = "https://raw.githubusercontent.com/nghehoang007-wq/HFB321/main/HFB/Thump/nguonphat5.png"
              try:
                  bg_res = requests.get(base_bg_url, timeout=10)
                  base_bg = Image.open(io.BytesIO(bg_res.content)).convert("RGBA")
                  base_bg = base_bg.resize((640, 360))
              except:
                  base_bg = Image.new('RGBA', (640, 360), (0, 0, 0, 255)) # N·ªÅn ƒëen d·ª± ph√≤ng

              response = requests.get(API_URL, headers=HEADERS, impersonate="chrome110", timeout=30)
              data = response.json()
              matches = data.get('matches', [])

              master_json = {
                  "id": "chuoichienhfb",
                  "url": "https://nghehoang007-wq.github.io/HFB321/chuoichientv.json",
                  "name": "Chu·ªëi Chi√™n TV",
                  "color": "#003A17",
                  "description": "C·∫≠p nh·∫≠t tr·ª±c ti·∫øp t·ª´ Chu·ªëi Chi√™n TV",
                  "image": {"url": "https://scontent.fhan14-2.fna.fbcdn.net/v/t39.30808-6/616798132_837736625898942_6926473979861361436_n.jpg?_nc_cat=108&ccb=1-7&_nc_sid=1d70fc&_nc_ohc=Z6CXRwgTFn8Q7kNvwF-Svp8&_nc_oc=Adl8bSYZaT51msTbE0n_zgDSMTNA1_WgGIf_8wmFhFd_ql1qVSqxingf-OpM32ywK_o&_nc_zt=23&_nc_ht=scontent.fhan14-2.fna&_nc_gid=To0o9HmHhAIOkqnd4cTYKQ&_nc_ss=8&oh=00_Afs2wsTDkdhTalw3AGj_UTR01x1mbGY22gUJXqbZL6vrcA&oe=69A8D9D1"},
                  "groups": [{"id": "live", "name": "üî¥ TR·ª∞C TI·∫æP CHU·ªêI CHI√äN", "display": "vertical", "grid_number": 2, "channels": []}],
                  "notice": {"id": "notice", "link": "https://t.me/xemgicungshare", "icon": "https://tt.8share.pro/assets/telegram_sp.png", "closeable": True},
                  "option": {"save_history": False, "save_search_history": False, "save_wishlist": False}
              }
              
              count = 0
              for match in matches:
                  try:
                      match_id = match.get('_id')
                      teams_data = match.get('teams', {})
                      home_data = teams_data.get('home', {})
                      away_data = teams_data.get('away', {})
                      
                      team1_full = home_data.get('name', 'Home')
                      team2_full = away_data.get('name', 'Away')
                      team1_short = shorten_name(team1_full)
                      team2_short = shorten_name(team2_full)
                      home_logo = home_data.get('logo', '')
                      away_logo = away_data.get('logo', '')

                      # X·ª¨ L√ù TH·ªúI GIAN
                      match_time_raw = match.get('matchTime', '')
                      time_display = "00h00"
                      if match_time_raw:
                          try:
                              dt = parser.parse(match_time_raw).astimezone(tz_vn)
                              time_display = dt.strftime("%Hh%M")
                          except: pass

                      blvs_list = match.get('blvs', [])
                      if not blvs_list: continue
                      blv = blvs_list[0]
                      blv_name = blv.get('name', 'Chu·ªëi')
                      streams = blv.get('streams', [])
                      if not streams: continue

                      # -- S·∫¢N XU·∫§T ·∫¢NH THUMBNAIL (L·ªíNG LOGO) --
                      thumb_url = base_bg_url # M·∫∑c ƒë·ªãnh n·∫øu l·ªói
                      try:
                          bg_copy = base_bg.copy()
                          has_new_logo = False
                          
                          if home_logo:
                              h_res = requests.get(home_logo, timeout=5)
                              if h_res.status_code == 200:
                                  h_img = Image.open(io.BytesIO(h_res.content)).convert("RGBA")
                                  h_img = h_img.resize((120, 120))
                                  # D√°n logo b√™n tr√°i
                                  bg_copy.paste(h_img, (100, 100), h_img)
                                  has_new_logo = True
                                  
                          if away_logo:
                              a_res = requests.get(away_logo, timeout=5)
                              if a_res.status_code == 200:
                                  a_img = Image.open(io.BytesIO(a_res.content)).convert("RGBA")
                                  a_img = a_img.resize((120, 120))
                                  # D√°n logo b√™n ph·∫£i
                                  bg_copy.paste(a_img, (420, 100), a_img)
                                  has_new_logo = True
                                  
                          if has_new_logo:
                              thumb_path = f"thumbs/{match_id}.png"
                              bg_copy.save(thumb_path, "PNG")
                              thumb_url = f"{BASE_THUMB_URL}{match_id}.png"
                      except Exception as e:
                          print(f"L·ªói t·∫°o ·∫£nh tr·∫≠n {match_id}: {e}")

                      # -- T·∫†O FILE JSON CON --
                      child_json = {"stream_links": []}
                      master_streams = []
                      for idx, s in enumerate(streams):
                          s_url = s.get('url')
                          s_name = f"{blv_name} - {s.get('label', 'HD')}"
                          if not s_url: continue
                          
                          child_json["stream_links"].append({
                              "id": str(idx+1), "name": s_name, "type": "hls" if "m3u8" in s_url else "flv",
                              "url": s_url, "default": idx==0,
                              "request_headers": [{"key": "Referer", "value": "https://api.chuoichientv.com/"}]
                          })
                          master_streams.append({"id": f"{match_id}_{idx}", "name": s_name, "remote_data": {"url": f"{BASE_REMOTE_URL}{match_id}.json"}})

                      if not master_streams: continue
                      with open(f"stream/{match_id}.json", "w", encoding="utf-8") as f:
                          json.dump(child_json, f, ensure_ascii=False, indent=2)

                      # -- GIAO DI·ªÜN K√äNH --
                      labels = [
                          {"position": "bottom-center", "text": time_display, "color": "#FF0000", "text_color": "#FFFFFF"},
                          {"position": "center-left", "text": team1_short, "color": "#80000000", "text_color": "#FFFFFF"},
                          {"position": "center-right", "text": team2_short, "color": "#80000000", "text_color": "#FFFFFF"}
                      ]

                      master_json["groups"][0]["channels"].append({
                          "id": match_id, 
                          "name": f"{team1_full} vs {team2_full}",
                          "labels": labels,
                          "image": {"url": thumb_url, "height": 360, "width": 640, "display": "cover"},
                          "type": "single", 
                          "display": "thumbnail-only",
                          "sources": [{"id": f"src-{match_id}", "name": "Chu·ªëi Chi√™n", "contents": [{"id": f"c-{match_id}", "name": f"{team1_full} vs {team2_full}", "streams": master_streams}]}]
                      })
                      count += 1
                  except Exception as e:
                      print(f"B·ªè qua 1 tr·∫≠n do l·ªói: {e}")
                      continue

              with open('chuoichientv.json', 'w', encoding='utf-8') as f:
                  json.dump(master_json, f, ensure_ascii=False, indent=2)
              print(f"üéâ TH√ÄNH C√îNG! N·∫°p {count} tr·∫≠n v√† t·∫°o xong Thumbnail Logo l·ªìng.")
          except Exception as e: 
              print(f"L·ªói t·ªïng th·ªÉ: {e}")
          EOF
          python3 scraper.py

      - name: Commit and Push
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          
          # ƒê·∫©y th√™m c·∫£ th∆∞ m·ª•c thumbs ch·ª©a ·∫£nh ƒë√£ ƒë∆∞·ª£c "Photoshop"
          git add -A stream/
          git add -A thumbs/
          git add chuoichientv.json
          
          git commit -m "Auto Photoshop Logos & Robust Fix" || echo "No changes"
          git push
